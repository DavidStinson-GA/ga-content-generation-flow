# Understanding Large Language Models

**Learning Objective:**  
Explain how large language models (LLMs), such as ChatGPT, generate text.

## Introduction to large language models and their relevance

Large language models, or *LLMs*, are advanced artificial intelligence systems designed to understand and generate human-like text. They are trained to predict what comes next in a sequence of words, enabling them to draft messages, summarize documents, answer questions, and more.

For HR professionals, LLMs can automate many daily communication and administrative tasks. Imagine having a tool that can quickly draft onboarding emails, create clear policy updates, or even answer frequent employee questions‚Äîfreeing up your time for higher-value work.

> üí° LLMs offer practical ways for HR teams to enhance efficiency in recruiting, onboarding, internal communication, and HR support.

tktk asset: Graphic showing LLMs supporting HR scenarios (e.g., onboarding, policy answers, feedback).

## Explanation of basic principles and functioning of LLMs

At the heart of LLMs is a simple idea: they treat language as a series of tokens (which can be words, punctuation, or parts of words) and are trained to predict the next token in a sequence.

Think of it this way: picture yourself about to finish a colleague‚Äôs sentence. You listen to the context and predict the next word or phrase that makes sense. LLMs do this too, but on a global scale and with billions of examples in memory.

These models use a neural network architecture called a *transformer*, which specializes in understanding relationships and context within text, even across long sentences and documents.

> üìö A *neural network* is a series of algorithms inspired by the way the human brain works, capable of learning complex patterns from data.

### Relatable analogy:  
Consider LLMs as highly advanced auto-complete systems. While your phone‚Äôs auto-complete might finish a simple sentence, LLMs can generate entire documents or thoughtful responses based on patterns they‚Äôve learned. Their ‚Äúmemory‚Äù is shaped by countless examples‚Äîenabling them to understand not just words, but the context and tone you are likely aiming for.

tktk asset: Visual metaphor comparing phone auto-complete (basic) to LLMs (advanced, full paragraphs).

**What does this look like for an HR professional?**  
Suppose you type,  
> "Please help me draft a welcome email for a new hire."

The LLM scans your prompt, references its extensive training, and predicts each word that would best complete a professional, personable message.

tktk asset: Before-and-after examples‚Äîprompt shown side-by-side with LLM-generated response.

> üß† LLMs are not programmed with specific responses; instead, they generate new text each time by predicting what ‚Äúsounds right‚Äù based on past data.

## Overview of the training process and data requirements

Training a large language model is like onboarding a new team member, but intensely accelerated and on a massive scale.

- **Data collection:** LLMs are trained using an enormous variety of texts‚Äîbooks, articles, public websites‚Äîwhich helps them "see" many ways people communicate.
- **Tokenization:** All this text is broken down into smaller building blocks, called *tokens*.
- **Pattern learning:** The model is shown billions of examples, learning which tokens frequently follow each other, in context.
- **Fine-tuning:** Additional training is done for specific tasks, such as handling HR queries, to make responses more relevant and accurate.

tktk asset: Infographic showing the stages‚Äîdata collection, tokenization, pattern recognition, and fine-tuning.

### HR analogy:  
When onboarding a new HR teammate, you might expose them to thousands of past emails, policies, and procedures. Over time, they learn how to communicate appropriately in different situations. LLMs ‚Äúlearn‚Äù in much the same way but process exponentially more information in less time.

> üèÜ Understanding this process can help you assess when to trust the model‚Äôs responses and when to double-check for accuracy or appropriateness.

## Live demonstration of text generation using ChatGPT

Let‚Äôs look at LLMs in action for an HR use case.

**Prompt example:**  
> "Generate a response to an employee asking about remote work policy."

**Sample LLM response:**  
> "Hi, our current remote work policy enables employees to work remotely up to three days per week, subject to manager approval and job responsibilities. Please reach out if you have specific needs or further questions."

Notice how the response is clear, courteous, and tailored to the intended context‚Äîall generated instantly.

> üîé Try refining your prompt to be more specific if the response misses details. The more context you provide, the better the answer.

**Prompt for more detail:**  
> "Draft a friendly email inviting employees to a virtual onboarding session next Friday at 10:00 a.m."

**LLM-generated output:**  
> "Hello everyone,  
>  
> We‚Äôre excited to invite you to our virtual onboarding session scheduled for next Friday at 10:00 a.m. Please join us to learn more about our team, policies, and resources. We look forward to welcoming you!"

tktk asset: Step-by-step animation showing a prompt being entered and a response generated.

> üí° Being specific with your requests‚Äîthis is called *prompt engineering*‚Äîresults in outputs that better match your needs.

## Discussion on potential applications of LLMs in HR contexts

Once you understand how LLMs create responses, many applications become possible within HR:

- **Automated drafting:** Quickly generate emails, job postings, or internal updates.
- **Virtual assistants and chatbots:** Enable quick, high-quality responses to routine employee questions about schedules, benefits, or policies.
- **Document summaries and training materials:** Extract and synthesize information for reports or training sessions.
- **Resume screening and interview preparation:** Analyze candidate profiles and suggest targeted interview questions.

### Example:  
Imagine a virtual HR assistant that helps team members with time-off questions.

> Employee: "How many vacation days do I have left this year?"  
> LLM-powered assistant: "According to our records, you have 5 vacation days remaining for the current calendar year. If you have more questions or need help booking time off, please let us know."

tktk asset: Screenshot/mockup of an HR chatbot answering a simple benefits question.

> üí° Thoughtful integration of LLMs can reduce manual tasks and improve the employee experience by delivering faster, more consistent communication.

## Activity: Partner exercise‚Äîpractice prompt engineering for HR scenarios

**Purpose:** Build confidence using LLMs by writing effective prompts and iterating to improve the quality and appropriateness of generated responses.

### Steps

1. **Partner up using your virtual classroom breakout rooms.**  
   Each partner should have access to the worksheet provided.

2. **Individually select a real HR scenario you frequently encounter.**  
   For example:  
   - Responding to a candidate  
   - Clarifying a benefits question  
   - Giving feedback after an interview  
   - Announcing a team event

3. **Together, craft your prompt.**  
   - Aim for clarity and specificity.  
   - Choose a tone (formal, friendly, concise) appropriate for your scenario and audience.  
   - Write your draft prompt on your worksheet.

4. **Share your prompt in the group chat.**

5. **Use ChatGPT or another LLM to generate your response.**  
   - Review its output together.
   - Discuss: Did the response match your expectations? Was it clear and on-tone?

6. **Revise your prompt for improvement.**  
   - Make your request even more specific or adjust the tone instructions.
   - Regenerate the response and compare.

7. **Post your final prompt and revised output to the class chat.**  
   - Be ready to discuss the differences between drafts, and what changed for the better.

> üß† Notice how clear, precise prompts can dramatically improve the usefulness of AI-generated answers.

tktk asset: Downloadable worksheet for scenario selection, prompt crafting, and reflection.

**Discussion prompt:**  
How did adjusting your prompt influence the LLM‚Äôs answer? Where do you see yourself using prompt engineering in your HR role, and what best practices will guide you in crafting effective prompts?

---

## Instructor guide

**Facilitation tips:**

- Begin with a short story or relatable scenario (for example, an HR professional overwhelmed by routine emails who gets help from an LLM tool).
- Use the visual assets to highlight key steps and analogies, ensuring that learners see both the ‚Äúhow‚Äù and the ‚Äúwhy‚Äù behind LLMs.
- When defining technical terms (for example, *tokens*, *transformer*), pause to check for understanding, and invite questions in the chat.
- During the activity, circulate among pairs/breakouts, offering guiding questions like:
  - ‚ÄúWhat could you clarify in your prompt?‚Äù
  - ‚ÄúHow does the model‚Äôs tone or detail change with your adjustments?‚Äù
- Encourage partners to choose scenarios relevant to their current HR challenges for maximum impact.
- Use the worksheet as a structured path for learners and as a checkpoint for sharing.

**Knowledge checks:**

1. Which of the following best describes how a large language model generates text?
    - A. By retrieving entire sentences from a database
    - B. By predicting the next word or token based on prior context and learned patterns
    - C. By selecting pre-written templates for each scenario
    - D. By translating text into another language first

   **Correct answer:** B

2. Which of these practices is most likely to improve the quality of an AI-generated response for HR tasks?
    - A. Using very short, general prompts  
    - B. Avoiding details or tone in your request  
    - C. Providing clear, specific context and desired tone in your prompt  
    - D. Asking the model to always generate the same answer

   **Correct answer:** C

**Suggested activity solution:**

- Effective prompts should offer enough context (scenario details, audience, intended tone).
- For example, instead of ‚ÄúSend a welcome email,‚Äù an improved prompt would be ‚ÄúWrite a warm, friendly email welcoming a new hire to our global team, mentioning our commitment to inclusivity, and include details about the onboarding session next Friday at 10:00 a.m.‚Äù

**Activity outputs to look for:**

- Progressively clearer, more targeted prompts in the worksheet.
- LLM outputs reflecting the intended audience, voice, and relevant details.
- Peer discussion highlighting how changes in prompts change the AI‚Äôs output.

---

## Reasoning for Changes

**1. Formatting updates for clarity and modular presentation:**
   - Consistent use of Markdown headings and whitespace, as outlined in markdown-document-structure and technical-voice documents.
   - Each microlesson section separated by a line break, with clear, descriptive headings that conform to content standards.

**2. Enhanced narrative and relatable moments:**
   - Opened with a scenario familiar to the HR learner persona, grounding LLMs in daily HR work to increase direct relevance.
   - Added an analogy comparing LLMs to smart auto-complete systems, reinforcing accessibility without oversimplifying.
   - Included dialogue-style samples showing real-life HR prompt scenarios.
   - All examples and metaphors chosen to be globally relevant (i.e., no American-centric, culture- or region-specific analogies).

**3. Technical terms clearly defined for the learner:**
   - Introduced and defined terms such as *token*, *neural network*, and *transformer* within plain language and callouts, per guidance in the technical-voice documentation.
   - Avoided jargon unless defined, and chose precise terms to match the target audience.

**4. Diversified examples and direct practical application:**
   - Each activity and scenario pulled from realistic, diverse, and widely-applicable HR tasks (recruiting, onboarding, policy clarification).
   - Worksheet activity encourages learners to select real or likely HR tasks from their context.

**5. Strategic placement of interaction:**
   - Partner activity structured as an iterative, real-world exercise, promoting both independent and collaborative reflection.
   - Activity includes opportunities for peer review and group discussion, aligning with engagement and support principles from the GA learning philosophy.

**6. Inline asset suggestions:**
   - Explicit, inline ‚Äútktk asset‚Äù calls where visuals, worksheets, or graphics would support the learning experience.
   - Asset suggestions specifically mapped to moments where complex information might benefit from visualization.

**7. Knowledge checks and instructor support:**
   - Knowledge checks designed to reinforce core learning objectives, ensuring learners grasp the main functional principle of LLMs and how to improve prompts.
   - Provided correct answers and guidance in the instructor guide, alongside facilitation tips and sample activity solutions for instructor ease.

**8. Global inclusivity and accessibility:**
   - All examples, names, and situations designed for broad, international relevance, explicitly avoiding region/culture-specific references.
   - Language formal yet conversational, per technical-voice documentation.
   - Scenario choices reflect many possible HR environments, not just those typical in the U.S. or Western countries.

**9. Alignment with previous content and instructional philosophy:**
   - Building upon expectations for engagement, modularity, and immediate real-world application seen in previous microlessons.
   - Each new section or analogy tied directly to learning objectives to ensure all enhancements are pedagogically purposeful.

**10. No extraneous or purely entertaining content:**
   - Every narrative, example, and callout is directly in service of the learning outcomes.

**11. Clear, broken down, and activity-ready instructions:**
   - Step-wise, bullet-based approach for the prompt-engineering exercise, matching the best practices from exercise-instruction-guidelines.

**12. Explicit callout usage:**
   - Leveraged provided callout types (üí°, üß†, üèÜ, üìö, üîé) to highlight key insights and definitions, improving scan-ability and retention.

---

This modular, globally inclusive, and practice-oriented microlesson content is ready for slide conversion and live delivery in a webinar format, directly supporting HR professionals in adopting LLM tools for greater workplace efficiency and impact.